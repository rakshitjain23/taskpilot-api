# TaskPilot API

TaskPilot API is the robust backend service for the TaskPilot project management application. Built with modern Python technologies, it provides a scalable foundation for managing workspaces, projects, tasks, and real-time team collaboration.

## ğŸš€ Key Features

*   **ğŸ” Secure Authentication**: Full JWT-based generic authentication system with secure password hashing.
*   **ğŸ¢ Workspace Management**: Multi-tenant architecture allowing users to create and manage isolated workspaces.
*   **ğŸ“Š Project & Task Tracking**: Comprehensive project lifecycles with granular task management (status updates, priorities, assignments).
*   **ğŸ’¬ Collaboration Tools**: Real-time commenting system on tasks to facilitate team communication.
*   **ğŸ¤– Context-Aware AI**: Integrated **DeepSeek AI** assistant that understands your project context (tasks, deadlines, members) to provide intelligent suggestions.
*   **ğŸ“œ Activity Logging**: Detailed audit trails for all user actions within workspaces and projects.
*   **ğŸ›¡ï¸ Role-Based Access Control**: Granular permission systems for workspace members (Admins, Members, etc.).

## ğŸ› ï¸ Tech Stack

*   **Language**: Python 3.10+
*   **Web Framework**: [FastAPI](https://fastapi.tiangolo.com/) - High-performance, easy-to-learn, fast-to-code, ready-for-production.
*   **Database**: PostgreSQL - The world's most advanced open source relational database.
*   **ORM**: SQLAlchemy (Async) - The Python SQL Toolkit and Object Relational Mapper.
*   **Migrations**: Alembic - A lightweight database migration tool for usage with SQLAlchemy.
*   **Caching**: Redis - In-memory data store for caching and message brokerage.
*   **Async Tasks**: Celery - Distributed task queue for handling background jobs (emails, AI processing).
*   **Containerization**: Docker & Docker Compose - For consistent development and deployment environments.

## ğŸ“‚ Detailed File Structure

```text
taskpilot-api/
â”œâ”€â”€ alembic/                # Database migration scripts and revisions
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ v1/             # API Version 1 endpoints
â”‚   â”‚       â”œâ”€â”€ routes_auth.py          # Login, Register, Refresh Token
â”‚   â”‚       â”œâ”€â”€ routes_users.py         # User profile management
â”‚   â”‚       â”œâ”€â”€ routes_workspaces.py    # Workspace CRUD & settings
â”‚   â”‚       â”œâ”€â”€ routes_workspace_members.py # Member management
â”‚   â”‚       â”œâ”€â”€ routes_projects.py      # Project creation & tracking
â”‚   â”‚       â”œâ”€â”€ routes_tasks.py         # Task assignment & status
â”‚   â”‚       â”œâ”€â”€ routes_comments.py      # Task comments
â”‚   â”‚       â”œâ”€â”€ routes_activity_logs.py # User activity history
â”‚   â”‚       â””â”€â”€ routes_ai.py            # AI assistant endpoints
â”‚   â”œâ”€â”€ core/               # Application capability configuration
â”‚   â”‚   â”œâ”€â”€ config.py           # Environment variables (Pydantic BaseSettings)
â”‚   â”‚   â”œâ”€â”€ security.py         # JWT handling & Password hashing
â”‚   â”‚   â””â”€â”€ logging_config.py   # Structured logging setup
â”‚   â”œâ”€â”€ db/                 # Database layer
â”‚   â”‚   â”œâ”€â”€ session.py          # Async session factory
â”‚   â”‚   â”œâ”€â”€ base.py             # SQLAlchemy Declarative Base
â”‚   â”‚   â””â”€â”€ init_db.py          # Initial data seeding script
â”‚   â”œâ”€â”€ models/             # SQLAlchemy Database Tables
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ workspace.py
â”‚   â”‚   â”œâ”€â”€ project.py
â”‚   â”‚   â”œâ”€â”€ task.py
â”‚   â”‚   â”œâ”€â”€ comment.py
â”‚   â”‚   â”œâ”€â”€ activity_log.py
â”‚   â”‚   â””â”€â”€ ai_request.py
â”‚   â”œâ”€â”€ schemas/            # Pydantic Models (Data Transfer Objects)
â”‚   â”‚   â”œâ”€â”€ user_schema.py
â”‚   â”‚   â”œâ”€â”€ task_schema.py
â”‚   â”‚   â”œâ”€â”€ project_schema.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ services/           # Business Logic Layer
â”‚   â”‚   â”œâ”€â”€ ai_service.py       # AI Context & DeepSeek integration
â”‚   â”‚   â”œâ”€â”€ project_service.py  # Project-related logic
â”‚   â”‚   â”œâ”€â”€ task_service.py     # Complex task operations
â”‚   â”‚   â””â”€â”€ deepseek_client.py  # External AI API client
â”‚   â”œâ”€â”€ tasks/              # Celery Background Tasks
â”‚   â”‚   â”œâ”€â”€ ai_tasks.py         # Async AI processing
â”‚   â”‚   â””â”€â”€ email_tasks.py      # Async email notifications
â”‚   â”œâ”€â”€ utils/              # Shared Utilities
â”‚   â”œâ”€â”€ celery_app.py       # Celery application configuration
â”‚   â””â”€â”€ main.py             # Application entrypoint & middleware
â”œâ”€â”€ docker-compose.yml      # Orchestration for API, DB, and Redis
â”œâ”€â”€ Dockerfile              # Production-ready Docker image
â””â”€â”€ requirements.txt        # Python dependencies
```

## âš¡ Getting Started

### Prerequisites

*   **Docker** and **Docker Compose** installed (recommended).
*   (Optional) **Python 3.10+** and **PostgreSQL** for local setup.

### ğŸ³ Running with Docker (Quickstart)

1.  **Clone the repository:**
    ```bash
    git clone <repository_url>
    cd taskpilot-api
    ```

2.  **Environment Setup:**
    Create a `.env` file in the root directory (copy the example structure below).

3.  **Start the Stack:**
    ```bash
    docker-compose up --build
    ```
    This spins up:
    *   **API Service**: `http://localhost:8000`
    *   **PostgreSQL**: Port `5432`
    *   **Redis**: Port `6379`

4.  **Explore the API:**
    Open your browser to **`http://localhost:8000/docs`** for the interactive Swagger UI.

### ğŸ’» Local Development (Manual)

1.  **Set up Virtual Environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Windows: venv\Scripts\activate
    ```

2.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Start Logic Dependencies:**
    Use Docker to run just the DB and Cache:
    ```bash
    docker-compose up db redis -d
    ```

4.  **Apply Migrations:**
    ```bash
    alembic upgrade head
    ```

5.  **Run API:**
    ```bash
    uvicorn app.main:app --reload
    ```

## âš™ï¸ Configuration

Create a `.env` file in the root directory.

```env
# --- Security ---
SECRET_KEY=change_this_to_a_secure_random_string
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# --- Database ---
# Local execution:
DATABASE_URL=postgresql+asyncpg://postgres:password@localhost:5432/taskpilot
# Docker execution (service name 'db'):
# DATABASE_URL=postgresql+asyncpg://postgres:password@db:5432/taskpilot

# --- Redis ---
# Local execution:
REDIS_URL=redis://localhost:6379/0
# Docker execution (service name 'redis'):
# REDIS_URL=redis://redis:6379/0

# --- AI Integration (DeepSeek) ---
DEEPSEEK_API_KEY=your_deepseek_api_key_here
```

## ğŸ¤ Contributing

1.  Fork the project.
2.  Create your feature branch (`git checkout -b feature/AmazingFeature`).
3.  Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4.  Push to the feature branch (`git push origin feature/AmazingFeature`).
5.  Open a Pull Request.
